{"cells":[{"cell_type":"markdown","source":["#ENTREGA FINAL: TEXTO\n","\n","##AUTORES: Antonio Gonzalez Suarez, Fernando Revuelta San Emeterio y Agustín Rodríguez Agudo\n"],"metadata":{"id":"3WXc_SQt3QaM"}},{"cell_type":"markdown","source":["## INTRODUCCIÓN\n"," + La generación automática de texto clínico es una tarea fundamental en el campo de la medicina, con aplicaciones que van desde la documentación de historias clínicas hasta la redacción de informes médicos completos. En los últimos años, los modelos de lenguaje preentrenados han demostrado ser herramientas poderosas para abordar este desafío. Sin embargo, para lograr un rendimiento óptimo en el contexto médico, es necesario adaptar estos modelos a datos específicos de informes médicos.\n","\n"," + El objetivo de este trabajo práctico es explorar y aplicar el concepto de  fine tune LM utilizando datos específicos de informes médicos. Al aprovechar un modelo de lenguaje preentrenado como punto de partida, podemos beneficiarnos de su conocimiento general del lenguaje y luego ajustarlo a un dominio médico más especializado."],"metadata":{"id":"Ox48S-eh3Xb6"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42719,"status":"ok","timestamp":1684333907895,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"},"user_tz":-120},"id":"SuMwaWEKr4Fj","outputId":"2e7dad3b-3d17-4ef7-a277-0d81f111bed2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.26.0\n","  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.0) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.26.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.26.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.26.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.26.0) (3.4)\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.29.2\n","    Uninstalling transformers-4.29.2:\n","      Successfully uninstalled transformers-4.29.2\n","Successfully installed transformers-4.26.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (3.31.0)\n","Requirement already satisfied: aiofiles in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio) (3.8.4)\n","Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.95.2)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.0)\n","Requirement already satisfied: gradio-client>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.2.5)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.0)\n","Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.14.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n","Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n","Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from gradio) (3.8.12)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.7)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n","Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n","Requirement already satisfied: semantic-version in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.22.0)\n","Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.3)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (2023.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n","Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2022.7.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.3.1)\n","Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.27.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2022.12.7)\n","Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (0.17.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (1.26.15)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n","Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.6)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"]}],"source":["# Requirements\n","\n","!pip install transformers==4.26.0\n","!pip install datasets\n","!pip install gradio\n","!pip install openai"]},{"cell_type":"markdown","source":["## CONFIGURACIONES PREVIAS"],"metadata":{"id":"DkJ2qLQ17670"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"gk5-yUB1sATv","executionInfo":{"status":"ok","timestamp":1684333917831,"user_tz":-120,"elapsed":9974,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"}}},"outputs":[],"source":["# Imports\n","\n","from google.colab import drive \n","import os\n","import sys\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import re\n","from functools import reduce\n","\n","from datasets import DatasetDict, Dataset, load_dataset\n","from transformers import AutoTokenizer, DataCollatorForLanguageModeling, DefaultDataCollator, AutoModelForMaskedLM, AutoModelForQuestionAnswering, pipeline, Trainer, TrainingArguments, EarlyStoppingCallback\n","\n","import gradio as gr"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3081,"status":"ok","timestamp":1684333920875,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"},"user_tz":-120},"id":"TSBUnHhO7zS0","outputId":"319c29fd-4cb1-4c60-d498-ca59fa2ad904"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Mount drive\n","\n","drive.mount('/content/drive') "]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Co-oMrK673Ib","executionInfo":{"status":"ok","timestamp":1684333920879,"user_tz":-120,"elapsed":26,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"}}},"outputs":[],"source":["# Colab Path set up\n","\n","os.chdir(\"/content/drive/My Drive\") \n","sys.path.append(\"/content/drive/My Drive/\") \n","    \n","# Root directory of the project \n","ROOT_DIR = os.path.abspath(\".\") "]},{"cell_type":"markdown","source":["* Lectura y transformación del dataset médico."],"metadata":{"id":"hTlTDoFR8GAR"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"hTOJRJkgtP-5","executionInfo":{"status":"ok","timestamp":1684333926361,"user_tz":-120,"elapsed":5504,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"}}},"outputs":[],"source":["# Load data\n","\n","# Load the data from a pandas DataFrame\n","data = pd.read_csv(\"./lawLanguageModel/data/mtsamples.csv\")\n","data = data[['transcription']]\n","data.columns = ['text']\n","data.dropna(inplace=True)\n","data['text'] = list(map(lambda x: x.split('.'), data['text']))\n","flat = reduce(lambda x, y: x + y, data['text'])\n","data = pd.DataFrame({'text': flat})"]},{"cell_type":"code","source":["# Clean text\n","def clean_function(example):\n","  new_text = re.sub('([:,.+\\-%])', ' ', example)\n","  new_text = re.sub('\\s{1,}', ' ', new_text)\n","  return new_text.strip()\n","\n","data['text'] = list(map(clean_function, data['text']))"],"metadata":{"id":"ncsT15hQvsO1","executionInfo":{"status":"ok","timestamp":1684333931383,"user_tz":-120,"elapsed":4394,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Convert the DataFrame to a Hugging Face Dataset\n","\n","dataset = Dataset.from_pandas(data)\n","train_dataset, val_dataset = train_test_split(dataset, test_size=0.2)\n","train_dataset = Dataset.from_dict(train_dataset)\n","val_dataset = Dataset.from_dict(val_dataset)\n","dataset = DatasetDict({'train': train_dataset, 'validation': val_dataset})"],"metadata":{"id":"za-UumS6vx_I","executionInfo":{"status":"ok","timestamp":1684333939894,"user_tz":-120,"elapsed":7935,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["* *Bert base cased* es un modelo preentrenado ampliamente utilizado y popular en el campo del procesamiento del lenguaje natural. Algunas de las razones por las que se utiliza:\n","  + Representación contextual de palabras: Bert-base-cased cada palabra se representa teniendo en cuenta las palabras que la rodean, lo que permite capturar mejor el significado y la semántica de las palabras en función de su contexto. Esta representación contextualizada de las palabras es especialmente beneficiosa en tareas donde la comprensión y generación de texto de calidad son cruciales, como la generación de informes médicos.\n","\n","  + Cobertura de vocabulario extenso: Bert-base-cased utiliza un tokenizador de subpalabras que divide las palabras en unidades más pequeñas, lo que permite manejar eficientemente un vocabulario amplio. Esto es especialmente útil en el campo médico, donde se encuentran términos técnicos y científicos específicos."],"metadata":{"id":"a5lzSl_i8Wk9"}},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24226,"status":"ok","timestamp":1684333964114,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"},"user_tz":-120},"id":"868AnXaVsImu","outputId":"99657e53-ab6b-4e53-b49b-99548c2c525e"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# Load pre-trained model\n","\n","pretrained_model = \"bert-base-cased\"\n","tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n","model = AutoModelForMaskedLM.from_pretrained(pretrained_model)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["7ef1556dede64e64ae0ada16da494b6c","8e90afc3ad244e6991906aab00deaf56","4cf657e0b7d44de0b5da7a4b4beb0bc6","4b59c38d1fcd45cd966ed949c8df0aa6","45e4e334424f47c5b4068b00880dbe47","9760507e747741aba4359fd31d18bf48","8d7a587cbefb442993a24c9fa775b29a","1b3c11d39bb3410ea23ee3b3cafd125b","aae57f42ee2441ad8a4304d06e28bd98","bcdd6b5f3d564e8789c4b2cd5ff3a034","35f489f7c81b452eb0a09e6d764ffbac","164b6e1e88074bb28c1484880f61513d","2cdc1569050e4127b8bbaa69024d74f5","23e8e46eb8cc4fdb801cdcc5012208c4","085ee70f5d304cf494a74b7b9c58940a","2ca3ccc98d9840a19bd867c4a55e6ba5","6615746753184c05a002c229ece2490e","b1848848438e461db88d7eb1d91eb609","469b351374694359a0a183f49049010f","0efdf96c150940359d2f19b6c793bffe","90866709ce054d6380c6e6204740b4d8","62a2f189757f48c6bcd820719dc9c8f0"]},"id":"4uGHDDjBxWhE","outputId":"b2512258-638b-4e3b-972e-c06c6cb3cbfe","executionInfo":{"status":"ok","timestamp":1684333980564,"user_tz":-120,"elapsed":16495,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/181236 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ef1556dede64e64ae0ada16da494b6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/45309 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"164b6e1e88074bb28c1484880f61513d"}},"metadata":{}}],"source":["# Tokenize\n","\n","def tokenize_function(examples):\n","  return tokenizer(examples['text'], truncation = True, max_length = 150)\n","\n","dataset = dataset.map(tokenize_function, batched = True)"]},{"cell_type":"markdown","source":["+ Se limita el tamaño del dataset de entrenamiento ya que se requiere un tiempo considerable con un conjunto de datos tan extenso. El tamaño se elige según los recursos computacionales."],"metadata":{"id":"Rt0hSQ9R3i92"}},{"cell_type":"code","source":["# Limit training\n","dataset['train'] = Dataset.from_dict(dataset['train'][:5000])"],"metadata":{"id":"13xiHE665MZr","executionInfo":{"status":"ok","timestamp":1684333980980,"user_tz":-120,"elapsed":428,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"VBuIk4rasYbt","colab":{"base_uri":"https://localhost:8080/","height":716},"outputId":"f16a10a7-e79d-4790-8a62-b005bf2f3dae","executionInfo":{"status":"error","timestamp":1684334005304,"user_tz":-120,"elapsed":24335,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text. If text are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 5000\n","  Num Epochs = 50\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 7850\n","  Number of trainable parameters = 108340804\n","You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='46' max='7850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  46/7850 00:13 < 39:18, 3.31 it/s, Epoch 0.29/50]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<cell line: 33>\u001b[0m:\u001b[94m33\u001b[0m                                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1543\u001b[0m in \u001b[92mtrain\u001b[0m                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1540 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1541 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1542 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1543 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1544 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1545 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1546 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1796\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1793 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1794 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0margs.logging_nan_inf_filter                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1795 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m is_torch_tpu_available()                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1796 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[95mand\u001b[0m (torch.isnan(tr_loss_step) \u001b[95mor\u001b[0m torch.isinf(tr_loss_step))          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1797 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m):                                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1798 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# if loss is nan or inf simply add the average of previous logged lo\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1799 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mtr_loss += tr_loss / (\u001b[94m1\u001b[0m + \u001b[96mself\u001b[0m.state.global_step - \u001b[96mself\u001b[0m._globalstep_  \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mKeyboardInterrupt\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 33&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">33</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1543</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1540 │   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1541 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1542 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1543 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1544 │   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1545 │   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1546 │   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1796</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1793 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1794 │   │   │   │   │   </span>args.logging_nan_inf_filter                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1795 │   │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> is_torch_tpu_available()                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1796 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> (torch.isnan(tr_loss_step) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> torch.isinf(tr_loss_step))          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1797 │   │   │   │   </span>):                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1798 │   │   │   │   │   # if loss is nan or inf simply add the average of previous logged lo</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1799 │   │   │   │   │   </span>tr_loss += tr_loss / (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> + <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.global_step - <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._globalstep_  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n","</pre>\n"]},"metadata":{}}],"source":["# Train Args\n","training_args = TrainingArguments(\n","    # Output\n","    output_dir=\"./lawLanguageModel/tmp/ml_model\",\n","    overwrite_output_dir=True,\n","    # Gradient config\n","    num_train_epochs=50,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    learning_rate=5e-5,\n","    weight_decay = 0,\n","    warmup_steps = 100,\n","    no_cuda = False,\n","    # Checkpoint config\n","    evaluation_strategy='steps',\n","    save_steps=500,\n","    save_total_limit=1,\n","    load_best_model_at_end=True\n","    # metric_for_best_model (define compute_metrics function if necessary, if not takes loss function)\n",")\n","\n","# Fine-tune Model\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset['train'],\n","    eval_dataset=dataset['validation'],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=10, early_stopping_threshold=0.01)]\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uFwCNE2w9G_a"},"outputs":[],"source":["# Save Model\n","\n","trainer.save_model(\"./lawLanguageModel/tmp/ml_model/\")"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":5820,"status":"ok","timestamp":1684334018492,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"},"user_tz":-120},"id":"_WerxrVgVr7A","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e74b9785-617d-4817-8d38-4620b9ab4e5f"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file ./lawLanguageModel/tmp/ml_model/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"./lawLanguageModel/tmp/ml_model/\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.26.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file ./lawLanguageModel/tmp/ml_model/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"./lawLanguageModel/tmp/ml_model/\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.26.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file ./lawLanguageModel/tmp/ml_model/pytorch_model.bin\n","Generate config GenerationConfig {\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.0\"\n","}\n","\n","All model checkpoint weights were used when initializing BertForMaskedLM.\n","\n","All the weights of BertForMaskedLM were initialized from the model checkpoint at ./lawLanguageModel/tmp/ml_model/.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n","loading configuration file ./lawLanguageModel/tmp/ml_model/generation_config.json\n","Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.0\"\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Thank you so much Doctor, you are a nice person\n","Thank you so much Miss, you are a nice person\n","Thank you so much sir, you are a nice person\n","Thank you so much honey, you are a nice person\n","Thank you so much Mother, you are a nice person\n"]}],"source":["# Inference\n","\n","mask_filler = pipeline(\"fill-mask\", model=\"./lawLanguageModel/tmp/ml_model/\", tokenizer = tokenizer)\n","# mask_filler = pipeline(\"fill-mask\", model=\"bert-base-cased\", tokenizer = tokenizer) # Different result -> Trained\n","model.to('cpu') # Using Cuda when training\n","predicts = [el['sequence'] for el in mask_filler(\"Thank you so much [MASK], you are a nice person\")]\n","list(map(print, predicts));"]},{"cell_type":"markdown","source":[" + Nuevamente limitamos los datos con los que trajamos debido a los recuros temporales y computacionales."],"metadata":{"id":"H5yNUc1lDpmP"}},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":21540,"status":"ok","timestamp":1684334046143,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"},"user_tz":-120},"id":"Oy21mLKhFAO6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a1ad6c44-c55d-4181-882b-e45273705ea8"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"]}],"source":["# QA Dataset\n","\n","squad = load_dataset(\"squad\", split=\"train[:5000]\")\n","# squad = load_dataset(\"squad\", split=\"train\")\n","squad = squad.train_test_split(test_size=0.2)"]},{"cell_type":"markdown","source":["+ En el dataset se cuenta con la pregunta, la respuesta y el caracter de inicio de la repsuesta. Lo tokenizamos y buscamos los tokens iniciales y finales que contienen la respuesta, teniendo en cuenta el caso en el que esta truncada y no se encuentra disponible como resultado de la tokenizacion. "],"metadata":{"id":"eVspQWzoDz9f"}},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3451,"status":"ok","timestamp":1684334053651,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"},"user_tz":-120},"id":"HLy3_3pyFj_B","colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["a36fa0a51cdf412094b4347c0b6616f3","9f8f13e1f2b44088b2e795f603f1cae1","f8fa08e0c4cb45cf94adba54c958e315","2ac4490fca134034b4845bd304dfb23f","e0d551e7527b4c7c95eda42be9d08ed5","c57ad9d9e79845a7b625c627f8fcff5d","db61060e4cd044429e729bfb9d87a56a","fa4415f1232f4b6597147baf8b962312","655ebe5e2eb7405fbc21bc04c1c7b3f3","9c894b13c5f74715a511d8f8fc29bd46","6a117eeafa564587aea6467b6bc4a735","387200d33af94a0aa991440d4793f93d","61cf7408eacc41cb9183e412ca63414e","9d66b27537a9438c816da4c8b4d67afb","647f217c5ee640e587d6c2e97974acac","e69899bbb4a14880841d2deff4cd0457","1ad4f1f9b1524be1832de2c30b35ae4a","36cb740803e4449bbe27d615bdca3e43","6e56b872d0f44096b7196c30ab5911df","9b2c97d0c25b48f881382b25554b2873","af3e2590cb264d43b19baaa6599f3250","337fa448187c4b228968629df7fe67d4"]},"outputId":"00268d08-e4da-4cf6-dcca-dda112d8254e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a36fa0a51cdf412094b4347c0b6616f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"387200d33af94a0aa991440d4793f93d"}},"metadata":{}}],"source":["# QA Preprocess\n","\n","def preprocess_function(examples):\n","    # Tokenize\n","    questions = list(map(lambda x: x.strip(), examples[\"question\"]))\n","    inputs = tokenizer(\n","        questions,\n","        examples[\"context\"],\n","        max_length=200,\n","        truncation=\"only_second\",\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","    # Prepare iterations\n","    offset_mapping = inputs.pop(\"offset_mapping\")\n","    answers = examples[\"answers\"]\n","    start_positions = []\n","    end_positions = []\n","    # Iterate throught mapping on each example\n","    for i, offset in enumerate(offset_mapping):\n","        # Get character mapping\n","        answer = answers[i]\n","        start_char = answer[\"answer_start\"][0]\n","        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n","        # Token type (q, a or special tokens such as padding)\n","        sequence_ids = inputs.sequence_ids(i)\n","\n","        # Find the start and end of the context tokens (first token with 1, and last token with 1, before padding)\n","        idx = 0\n","        while sequence_ids[idx] != 1:\n","            idx += 1\n","        context_start = idx\n","        while sequence_ids[idx] == 1:\n","            idx += 1\n","        context_end = idx - 1\n","\n","        # If the answer is not fully inside the context (both side truncation), label it (0, 0)\n","        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n","            start_positions.append(0)\n","            end_positions.append(0)\n","        else:\n","            # Otherwise it's the start and end token positions\n","            # Search answer start token\n","            idx = context_start\n","            while idx <= context_end and offset[idx][0] <= start_char:\n","                idx += 1\n","            start_positions.append(idx - 1)\n","            # Search answer end token\n","            idx = context_end\n","            while idx >= context_start and offset[idx][1] >= end_char:\n","                idx -= 1\n","            end_positions.append(idx + 1)\n","    # Add answer start and end token\n","    inputs[\"start_positions\"] = start_positions\n","    inputs[\"end_positions\"] = end_positions\n","    return inputs\n","\n","squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)\n","data_collator = DefaultDataCollator()"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2721,"status":"ok","timestamp":1684334062992,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"},"user_tz":-120},"id":"nD3s5gxH-TB6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f98b29c4-7d1c-4d4d-dde1-95cbe74099db"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file ./lawLanguageModel/tmp/ml_model/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"./lawLanguageModel/tmp/ml_model/\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.26.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file ./lawLanguageModel/tmp/ml_model/pytorch_model.bin\n","Some weights of the model checkpoint at ./lawLanguageModel/tmp/ml_model/ were not used when initializing BertForQuestionAnswering: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ./lawLanguageModel/tmp/ml_model/ and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Load QA Model\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(\"./lawLanguageModel/tmp/ml_model/\")"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":10355,"status":"error","timestamp":1684334080199,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"},"user_tz":-120},"id":"YP6Tnd6QBLrM","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"c0b1a698-f7ec-4841-faa2-90bbe19acd31"},"outputs":[{"output_type":"stream","name":"stderr","text":["using `logging_steps` to initialize `eval_steps` to 500\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running training *****\n","  Num examples = 4000\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1250\n","  Number of trainable parameters = 107721218\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [   9/1250 00:07 < 20:49, 0.99 it/s, Epoch 0.06/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<cell line: 33>\u001b[0m:\u001b[94m33\u001b[0m                                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1543\u001b[0m in \u001b[92mtrain\u001b[0m                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1540 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1541 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1542 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1543 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1544 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1545 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1546 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1791\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1788 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m model.no_sync():                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1789 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1790 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1791 \u001b[2m│   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1792 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1793 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1794 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0margs.logging_nan_inf_filter                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2557\u001b[0m in \u001b[92mtraining_step\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2554 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# loss gets scaled under gradient_accumulation_steps in deepspeed\u001b[0m             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2555 \u001b[0m\u001b[2m│   │   │   \u001b[0mloss = \u001b[96mself\u001b[0m.deepspeed.backward(loss)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2556 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2557 \u001b[2m│   │   │   \u001b[0mloss.backward()                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2558 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2559 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m loss.detach()                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2560 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m487\u001b[0m in \u001b[92mbackward\u001b[0m                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/autograd/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m200\u001b[0m in \u001b[92mbackward\u001b[0m               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m200 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run the bac\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine to ru\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mKeyboardInterrupt\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 33&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">33</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1543</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1540 │   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1541 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1542 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1543 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1544 │   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1545 │   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1546 │   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1791</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1788 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> model.no_sync():                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1789 │   │   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1790 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1791 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1792 │   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1793 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1794 │   │   │   │   │   </span>args.logging_nan_inf_filter                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2557</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_step</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2554 │   │   │   # loss gets scaled under gradient_accumulation_steps in deepspeed</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2555 │   │   │   </span>loss = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.deepspeed.backward(loss)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2556 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2557 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss.backward()                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2558 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2559 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> loss.detach()                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2560 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">487</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 484 │   │   │   │   </span>create_graph=create_graph,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 485 │   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 487 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 489 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 │   # The reason we repeat same the comment below is that</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 │   # some Python versions print out the first line of a multi-line function</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   # calls in the traceback and some print out the last line</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the bac</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 │   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 │   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to ru</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n","</pre>\n"]},"metadata":{}}],"source":["# Train Args\n","training_args = TrainingArguments(\n","   # Output\n","    output_dir=\"./lawLanguageModel/tmp/qa_model\",\n","    overwrite_output_dir=True,\n","    # Gradient config\n","    num_train_epochs=10,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=16,\n","    learning_rate=5e-5,\n","    weight_decay = 0,\n","    warmup_steps = 100,\n","    no_cuda = False,\n","    # Checkpoint config\n","    evaluation_strategy='steps',\n","    save_steps=500,\n","    save_total_limit=1,\n","    load_best_model_at_end=True\n","    # metric_for_best_model (define compute_metrics functionif needed, if not takes loss)\n",")\n","\n","# Fine-tune Model\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=squad[\"train\"],\n","    eval_dataset=squad[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=10, early_stopping_threshold=0.01)]\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QR6TBwm6QjVy"},"outputs":[],"source":["# Save model\n","\n","trainer.save_model(\"./lawLanguageModel/tmp/qa_model/\")"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"4nSyMEhhBuhj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684334095274,"user_tz":-120,"elapsed":6661,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"}},"outputId":"c95ba52f-633d-4f6d-ec2a-189c064e8a42"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file ./lawLanguageModel/tmp/qa_model/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"./lawLanguageModel/tmp/qa_model/\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.26.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file ./lawLanguageModel/tmp/qa_model/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"./lawLanguageModel/tmp/qa_model/\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.26.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file ./lawLanguageModel/tmp/qa_model/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at ./lawLanguageModel/tmp/qa_model/.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n"]}],"source":["# Inference \n","model.to('cpu') # Using Cuda when trianing\n","question_answerer = pipeline(\"question-answering\", model=\"./lawLanguageModel/tmp/qa_model/\")\n","\n","def inference(context: str, question: str, question_answerer = question_answerer) -> str:\n","  return question_answerer(question=question, context=context)['answer']"]},{"cell_type":"code","source":["# Example\n","\n","context = \"BLOOM has 176 billion parameters and can generate text in 46 natural languages and 13 programming languages.\"\n","question = \"How many programming languages does BLOOM support?\"\n","inference(context, question, question_answerer)"],"metadata":{"id":"GjT0u8DKHpPt","executionInfo":{"status":"ok","timestamp":1684334107233,"user_tz":-120,"elapsed":302,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"}},"colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"2d0ae87c-3389-414e-d68e-9433e25bc294"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'13'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# Topic example\n","\n","context = \"The human body contains about 60% water. Water is essential for a variety of bodily functions, including regulating body temperature, transporting nutrients and oxygen to cells, and removing waste from the body. \"\n","question = \"How much water does the human body contain?\"\n","inference(context, question, question_answerer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"1pEbEBiY0iqS","executionInfo":{"status":"ok","timestamp":1684334119588,"user_tz":-120,"elapsed":677,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"}},"outputId":"3d900f8e-26e4-4537-8ceb-803088a48957"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'60%'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# Demo\n","\n","demo = gr.Interface(fn=inference, inputs=[\"text\", \"text\"], outputs=\"text\")\n","demo.launch()  "],"metadata":{"id":"Yl_avtkwG1Kb","executionInfo":{"status":"ok","timestamp":1684334121881,"user_tz":-120,"elapsed":590,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"}},"colab":{"base_uri":"https://localhost:8080/","height":616},"outputId":"1c1f549c-4355-4b35-87eb-714f30f9b6e9"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7860, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# Evaluation\n","# Query: Chat GPT\n","'''\n","Write in a json format a health or medical  context, a question about that context and an aswer to that question,  such as the answer to thas question is contained in the context:\n","{'context': ' ', 'question': ' ', 'answer': ' '}\n","'''\n","\n","\n","model.to('cpu')\n","question_answerer = pipeline(\"question-answering\", model=\"./lawLanguageModel/tmp/qa_model/\")\n","test_dataset = [{\n","    \"context\": \"Cardiovascular disease (CVD) is a group of conditions that affect the heart and blood vessels. The most common type of CVD is coronary artery disease, which is caused by a buildup of plaque in the arteries that supply blood to the heart. Other types of CVD include heart failure, stroke, and peripheral artery disease. Risk factors for CVD include smoking, high blood pressure, high cholesterol, diabetes, and a family history of the disease.\",\n","    \"question\": \"What are the risk factors for cardiovascular disease?\",\n","    \"answer\": \"Risk factors for CVD include smoking, high blood pressure, high cholesterol, diabetes, and a family history of the disease.\"\n","}]\n","list(map(lambda x: (question_answerer(question=x['question'], context=x['context'])['answer'], x['answer']), test_dataset))"],"metadata":{"id":"7wree42x4GjR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684333719447,"user_tz":-120,"elapsed":2259,"user":{"displayName":"Fernando Revuelta San Emeterio","userId":"15412016677517802137"}},"outputId":"9cf12e07-a18f-45cc-f3a0-94db9d518982"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Cardiovascular disease (CVD',\n","  'Risk factors for CVD include smoking, high blood pressure, high cholesterol, diabetes, and a family history of the disease.')]"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["+ Ejemplo de uso mediante la API de chat-GPT-4"],"metadata":{"id":"tgm2_eqJvo4K"}},{"cell_type":"code","source":["\"\"\"\n","import openai \n","\n","openai.api_key = \"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\"\n","\n","system_intel = \"You are GPT-4, answer my questions as if you were an expert in the field.\"\n","prompt = \"WWrite in a json format a health or medical  context, a question about that context and an aswer to that question,  such as the answer to thas question is contained in the context:{'context': ' ', 'question': ' ', 'answer': ' '}\"\n","\n","# Function that calls the GPT-4 API\n","def ask_GPT4(system_intel, prompt): \n","    result = openai.ChatCompletion.create(model=\"gpt-4\",\n","                                 messages=[{\"role\": \"system\", \"content\": system_intel},\n","                                           {\"role\": \"user\", \"content\": prompt}])\n","    return result['choices'][0]['message']['content']\n","\n","# Call the function above\n","test_dataset = ask_GPT4(system_intel, prompt)\n","list(map(lambda x: (question_answerer(question=x['question'], context=x['context'])['answer'], x['answer']), test_dataset))\n","\"\"\"\n","\n","\"\"\"\n","Devuelve algo como esto \n","{\n","  'context': 'Diabetes mellitus is a metabolic disease characterized by high blood sugar levels over a prolonged period. It is caused by the body's inability to produce or properly use insulin, which is essential in regulating blood sugar levels. Type 1 diabetes is typically caused by an autoimmune reaction, while Type 2 diabetes is primarily caused by lifestyle factors and genetics. Common symptoms of diabetes include increased thirst, frequent urination, extreme fatigue, and slow-healing wounds.',\n","  'question': 'What are the common symptoms of diabetes mellitus?',\n","  'answer': 'Increased thirst, frequent urination, extreme fatigue, and slow-healing wounds.'\n","}\n","\n","\"\"\"\n"],"metadata":{"id":"dL_RsxVtvT_H"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7ef1556dede64e64ae0ada16da494b6c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e90afc3ad244e6991906aab00deaf56","IPY_MODEL_4cf657e0b7d44de0b5da7a4b4beb0bc6","IPY_MODEL_4b59c38d1fcd45cd966ed949c8df0aa6"],"layout":"IPY_MODEL_45e4e334424f47c5b4068b00880dbe47"}},"8e90afc3ad244e6991906aab00deaf56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9760507e747741aba4359fd31d18bf48","placeholder":"​","style":"IPY_MODEL_8d7a587cbefb442993a24c9fa775b29a","value":"Map: 100%"}},"4cf657e0b7d44de0b5da7a4b4beb0bc6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b3c11d39bb3410ea23ee3b3cafd125b","max":181236,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aae57f42ee2441ad8a4304d06e28bd98","value":181236}},"4b59c38d1fcd45cd966ed949c8df0aa6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcdd6b5f3d564e8789c4b2cd5ff3a034","placeholder":"​","style":"IPY_MODEL_35f489f7c81b452eb0a09e6d764ffbac","value":" 181236/181236 [00:13&lt;00:00, 16843.58 examples/s]"}},"45e4e334424f47c5b4068b00880dbe47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"9760507e747741aba4359fd31d18bf48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d7a587cbefb442993a24c9fa775b29a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b3c11d39bb3410ea23ee3b3cafd125b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aae57f42ee2441ad8a4304d06e28bd98":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bcdd6b5f3d564e8789c4b2cd5ff3a034":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35f489f7c81b452eb0a09e6d764ffbac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"164b6e1e88074bb28c1484880f61513d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2cdc1569050e4127b8bbaa69024d74f5","IPY_MODEL_23e8e46eb8cc4fdb801cdcc5012208c4","IPY_MODEL_085ee70f5d304cf494a74b7b9c58940a"],"layout":"IPY_MODEL_2ca3ccc98d9840a19bd867c4a55e6ba5"}},"2cdc1569050e4127b8bbaa69024d74f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6615746753184c05a002c229ece2490e","placeholder":"​","style":"IPY_MODEL_b1848848438e461db88d7eb1d91eb609","value":"Map:  97%"}},"23e8e46eb8cc4fdb801cdcc5012208c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_469b351374694359a0a183f49049010f","max":45309,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0efdf96c150940359d2f19b6c793bffe","value":45309}},"085ee70f5d304cf494a74b7b9c58940a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90866709ce054d6380c6e6204740b4d8","placeholder":"​","style":"IPY_MODEL_62a2f189757f48c6bcd820719dc9c8f0","value":" 44000/45309 [00:02&lt;00:00, 17099.22 examples/s]"}},"2ca3ccc98d9840a19bd867c4a55e6ba5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"6615746753184c05a002c229ece2490e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1848848438e461db88d7eb1d91eb609":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"469b351374694359a0a183f49049010f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0efdf96c150940359d2f19b6c793bffe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90866709ce054d6380c6e6204740b4d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62a2f189757f48c6bcd820719dc9c8f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a36fa0a51cdf412094b4347c0b6616f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f8f13e1f2b44088b2e795f603f1cae1","IPY_MODEL_f8fa08e0c4cb45cf94adba54c958e315","IPY_MODEL_2ac4490fca134034b4845bd304dfb23f"],"layout":"IPY_MODEL_e0d551e7527b4c7c95eda42be9d08ed5"}},"9f8f13e1f2b44088b2e795f603f1cae1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c57ad9d9e79845a7b625c627f8fcff5d","placeholder":"​","style":"IPY_MODEL_db61060e4cd044429e729bfb9d87a56a","value":"Map: 100%"}},"f8fa08e0c4cb45cf94adba54c958e315":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa4415f1232f4b6597147baf8b962312","max":4000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_655ebe5e2eb7405fbc21bc04c1c7b3f3","value":4000}},"2ac4490fca134034b4845bd304dfb23f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c894b13c5f74715a511d8f8fc29bd46","placeholder":"​","style":"IPY_MODEL_6a117eeafa564587aea6467b6bc4a735","value":" 4000/4000 [00:02&lt;00:00, 1864.27 examples/s]"}},"e0d551e7527b4c7c95eda42be9d08ed5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"c57ad9d9e79845a7b625c627f8fcff5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db61060e4cd044429e729bfb9d87a56a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa4415f1232f4b6597147baf8b962312":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"655ebe5e2eb7405fbc21bc04c1c7b3f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c894b13c5f74715a511d8f8fc29bd46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a117eeafa564587aea6467b6bc4a735":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"387200d33af94a0aa991440d4793f93d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61cf7408eacc41cb9183e412ca63414e","IPY_MODEL_9d66b27537a9438c816da4c8b4d67afb","IPY_MODEL_647f217c5ee640e587d6c2e97974acac"],"layout":"IPY_MODEL_e69899bbb4a14880841d2deff4cd0457"}},"61cf7408eacc41cb9183e412ca63414e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ad4f1f9b1524be1832de2c30b35ae4a","placeholder":"​","style":"IPY_MODEL_36cb740803e4449bbe27d615bdca3e43","value":"Map: 100%"}},"9d66b27537a9438c816da4c8b4d67afb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e56b872d0f44096b7196c30ab5911df","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b2c97d0c25b48f881382b25554b2873","value":1000}},"647f217c5ee640e587d6c2e97974acac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af3e2590cb264d43b19baaa6599f3250","placeholder":"​","style":"IPY_MODEL_337fa448187c4b228968629df7fe67d4","value":" 1000/1000 [00:00&lt;00:00, 1079.19 examples/s]"}},"e69899bbb4a14880841d2deff4cd0457":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"1ad4f1f9b1524be1832de2c30b35ae4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36cb740803e4449bbe27d615bdca3e43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e56b872d0f44096b7196c30ab5911df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b2c97d0c25b48f881382b25554b2873":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af3e2590cb264d43b19baaa6599f3250":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"337fa448187c4b228968629df7fe67d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}